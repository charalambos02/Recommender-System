import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel
from surprise import Dataset, Reader, SVD
from surprise.model_selection import cross_validate, train_test_split
from surprise.accuracy import rmse
import warnings
from typing import Dict, List, Union
warnings.filterwarnings('ignore')
class HybridRecommender:
    def __init__(self, interactions_path='user_item_interactions.csv', 
                 metadata_path='item_metadata.csv', alpha=0.5):
        """Initialize the recommender system with data paths and hybrid weight.
        Args:
            interactions_path: Path to CSV with user-item interactions.
            metadata_path: Path to CSV with item metadata.
            alpha: Weight for collaborative filtering (0-1); content-based weight = 1-alpha.
        """
        self.alpha = alpha
        try:
            self.interactions = pd.read_csv(interactions_path)
            self.item_data = pd.read_csv(metadata_path)
            if not all(col in self.interactions.columns for col in ['user_id', 'item_id', 'rating']):
                raise ValueError("Interactions data missing required columns")
            if not all(col in self.item_data.columns for col in ['item_id', 'description']):
                raise ValueError("Item metadata missing required columns")
            self.item_data['description'] = self.item_data['description'].fillna('')
            self._init_collaborative_filtering()
            self._init_content_based_filtering()
            self._calculate_similarity_matrix()
        except Exception as e:
            print(f"Error initializing recommender: {str(e)}")
            raise
    def _init_collaborative_filtering(self):
        """Initialize collaborative filtering model (SVD)."""
        reader = Reader(rating_scale=(1, 5))
        data = Dataset.load_from_df(self.interactions[['user_id', 'item_id', 'rating']], reader)
        trainset = data.build_full_trainset()
        self.cf_model = SVD()
        self.cf_model.fit(trainset)
    def _init_content_based_filtering(self):
        """Initialize TF-IDF vectorizer and fit to item descriptions."""
        self.tfidf = TfidfVectorizer(stop_words='english')
        self.tfidf_matrix = self.tfidf.fit_transform(self.item_data['description'])
    def _calculate_similarity_matrix(self):
        """Precompute cosine similarity matrix for items."""
        self.cosine_sim = linear_kernel(self.tfidf_matrix, self.tfidf_matrix)
    def recommend(self, user_id: int, n: int = 5) -> List[Dict[str, Union[int, float]]]:
        """Generate hybrid recommendations for a user.
        Args:
            user_id: Target user ID.
            n: Number of recommendations to return.
        Returns:
            List of dictionaries with item IDs and hybrid scores.
        """
        # Collaborative filtering predictions
        all_items = self.item_data['item_id'].unique()
        cf_scores = {item: self.cf_model.predict(user_id, item).est for item in all_items}
        # Content-based filtering (fallback for cold-start)
        user_interactions = self.interactions[self.interactions['user_id'] == user_id]
        if len(user_interactions) == 0:  # Cold-start: use CB only
            cb_scores = {item: 1.0 for item in all_items}  # Placeholder logic
        else:
            last_item = user_interactions.iloc[-1]['item_id']
            idx = self.item_data[self.item_data['item_id'] == last_item].index[0]
            cb_scores = {item: self.cosine_sim[idx][i] for i, item in enumerate(all_items)}
        # Hybrid scores
        hybrid_scores = {
            item: self.alpha * cf_scores[item] + (1 - self.alpha) * cb_scores[item]
            for item in all_items
        }
        return sorted([{'item_id': k, 'score': v} for k, v in hybrid_scores.items()], 
                      key=lambda x: x['score'], reverse=True)[:n]